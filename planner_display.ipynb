{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# PLANNING GRAPH PART"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#%%\n",
    "\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "import numpy as np\n",
    "import numpy.random as rd\n",
    "from scipy import stats\n",
    "from planning_graph.planning_graph import PlanningGraph, NoOpAction\n",
    "from pddlpy.pddl import Operator\n",
    "from typing import Set, Tuple, List"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LayeredPlan. Levels=4\n",
      "0\n",
      "1\n",
      "<pddlpy.pddl.Operator object at 0x000001CED716BC10>\n",
      "<pddlpy.pddl.Operator object at 0x000001CED716BBE0>\n",
      "2\n",
      "<pddlpy.pddl.Operator object at 0x000001CED716B730>\n",
      "<pddlpy.pddl.Operator object at 0x000001CED716B580>\n",
      "3\n",
      "<pddlpy.pddl.Operator object at 0x000001CED716BCD0>\n",
      "<pddlpy.pddl.Operator object at 0x000001CED716BE20>\n"
     ]
    }
   ],
   "source": [
    "from planning_graph.planning_graph import PlanningGraph\n",
    "from planning_graph.planning_graph_planner import GraphPlanner\n",
    "\n",
    "\n",
    "planning_graph = PlanningGraph('domain/dock-worker-robot-domain.pddl', \n",
    "                               'domain/dock-worker-robot-problem.pddl')\n",
    "\n",
    "graph = planning_graph.create(max_num_of_levels=10)\n",
    "goal = planning_graph.goal\n",
    "graph_planner = GraphPlanner()\n",
    "layered_plan = graph_planner.plan(graph, goal)\n",
    "print(layered_plan)\n",
    "for i in range(len(layered_plan._layered_plan)):\n",
    "    print(i)\n",
    "    for a in (layered_plan[i]._plan):\n",
    "        if not isinstance(a, NoOpAction):\n",
    "            print(a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_feature_vec(planning_graph, state, max_level, visual = False, title = None):\n",
    "    # draw graph first\n",
    "    graph = planning_graph.create_with_state(state, max_num_of_levels=max_level, visualize = visual)\n",
    "    if title is not None and visual:\n",
    "        graph.visualize_png(title)\n",
    "    \n",
    "    # get action schema and output list\n",
    "    act_schema = np.array(list(planning_graph._planning_problem._domain_problem.operators())) # store names of total action schema\n",
    "    n = len(act_schema)  # length of action schema\n",
    "    feature_vec = np.zeros(n+2*n**2+3) # return feature vec, first n is linear, second 2*n**2 is pairwise, last 3 is additional feature\n",
    "    act_layers = list(graph.act.values()) # list of layers generated, ith value is the list of actions connencting i-1 th states to ith states layer\n",
    "\n",
    "    # extract linear feature\n",
    "    #-------------------------------------\n",
    "    # ith value indicate the num of occurance for ith action of act_schema in the entire graph \n",
    "    counter = np.zeros(n)\n",
    "    for act_layer in act_layers:\n",
    "        if act_layer is not None:\n",
    "            for a in act_layer:\n",
    "                 if not isinstance(a, NoOpAction):\n",
    "                        counter[act_schema == a.operator_name] += 1\n",
    "    feature_vec[0:n] = counter\n",
    "    \n",
    "    # extract pair-wise feature\n",
    "    #-------------------------------------\n",
    "    # each pair a1, a2 is stored in n + [2*(n*a1+a2), 2*(n*a1+a2)+1]\n",
    "    # e.g. when a1 is 1, a2 is 3, n is 5, store in 5 + [2*(8),  2*(8)+1]\n",
    "    def to_index(n, index_a1, index_a2, adder):\n",
    "        \"\"\"\n",
    "        return corresponding index in the position of the feature vector\n",
    "        adder is either 0 or 1\n",
    "        index_a1, index_a2 refer to move index in act_schema\n",
    "        \"\"\"\n",
    "        return n+2*(n*index_a1+index_a2)+adder\n",
    "    \n",
    "    \n",
    "    def append_to_dict(a, pre, eff_pos):\n",
    "        \"\"\"\n",
    "        add action a into the dicitonary pre and eff_pos\n",
    "        \"\"\"\n",
    "        for p in a.precondition_pos:\n",
    "            current = pre.get(p)\n",
    "            if current is None:\n",
    "                current = [a]\n",
    "            else:\n",
    "                current.append(a)\n",
    "            pre[p] = current\n",
    "            \n",
    "        for p in a.effect_pos:\n",
    "            current = eff_pos.get(p)\n",
    "            if current is None:\n",
    "                current = [a]\n",
    "            else:\n",
    "                current.append(a)\n",
    "            eff_pos[p] = current\n",
    "            \n",
    "#         for p in a.effect_neg:\n",
    "#             current = effect_neg.get(p)\n",
    "#             if current is None:\n",
    "#                 current = [name]\n",
    "#             else:\n",
    "#                 current.append(name)\n",
    "#             effect_neg[p] = current\n",
    "#         return pre, eff_pos, eff_neg\n",
    "            return pre, eff_pos\n",
    "\n",
    "\n",
    "    # define dictionary variables for comparison purpose\n",
    "    pre = {}\n",
    "    eff_pos = {}\n",
    "#     eff_neg = {}\n",
    "    \n",
    "    # add pre and eff into the empty dictionary for the first layer\n",
    "    for a in act_layers[1]:\n",
    "        if not isinstance(a, NoOpAction):\n",
    "            pre, eff_pos = append_to_dict(a, pre, eff_pos)\n",
    "   \n",
    "    # loop through second to last action layers\n",
    "    for i in range(2,len(act_layers)): \n",
    "        act_layer = act_layers[i]\n",
    "        \n",
    "        # update fecture vec for the entire layer\n",
    "        for a2 in act_layer:\n",
    "            if not isinstance(a2, NoOpAction):\n",
    "                # count for num of occurances, use set to avoid multiple countsc\n",
    "                s1 = set() # feature 1 where eff a1 and pre a2 has intersections\n",
    "                s2 = set() # feature 2 where pre a1 and eff a2 has intersections          \n",
    "                for p in a2.precondition_pos:\n",
    "                    current = eff_pos.get(p)\n",
    "                    if current is not None:\n",
    "                        for a1 in current:\n",
    "                            s1.add(a1) \n",
    "\n",
    "                for p in a2.effect_pos:\n",
    "                    current = pre.get(p)\n",
    "                    if current is not None:\n",
    "                        for a1 in current:\n",
    "                            s2.add(a1)\n",
    "                            \n",
    "                # add index to feature_vec based on set generated:\n",
    "                index_a2 = int(np.where(a2.operator_name == act_schema)[0])\n",
    "                for a1 in s1:\n",
    "                    # update feature 1 for pair (a1, a2)\n",
    "                    index_a1 = int(np.where(a1.operator_name == act_schema)[0])\n",
    "                    feature_vec[to_index(n, index_a1, index_a2,0)]+=1\n",
    "      \n",
    "                for a1 in s2:\n",
    "                    # update feature 2 for pair (a1, a2)\n",
    "                    index_a1 = int(np.where(a1.operator_name == act_schema)[0])\n",
    "                    feature_vec[to_index(n, index_a1, index_a2,1)]+=1\n",
    "\n",
    "        # update pre and eff_pos for the entire layer\n",
    "        for a2 in act_layer:\n",
    "            if not isinstance(a2, NoOpAction):\n",
    "                pre, eff_pos = append_to_dict(a2, pre, eff_pos)\n",
    "                \n",
    "                 \n",
    "    \n",
    "    # add heuristic value, number of layers and number of unsatisfied goals\n",
    "    goal = planning_graph.goal\n",
    "    graph_planner = GraphPlanner()\n",
    "    layered_plan = graph_planner.plan(graph, goal)\n",
    "    total_len = len(feature_vec)\n",
    "    # number of layers:\n",
    "    feature_vec[total_len - 3] = len(act_layers)\n",
    "    # heuristic value: (number of total plans in the layer)\n",
    "    h_v = 0\n",
    "    for i in range(len(layered_plan._layered_plan)):\n",
    "        for a in (layered_plan[i]._plan):\n",
    "            if not isinstance(a, NoOpAction):\n",
    "                h_v += 1\n",
    "    feature_vec[total_len - 2] = h_v\n",
    "    # unsatisfied goal (2 ** (last layer total pos num - goal state pos num))\n",
    "    last = graph.prop[len(graph.prop)-1]\n",
    "    feature_vec[total_len - 1] = 2 ** (len(last) - len(goal))\n",
    "    \n",
    "\n",
    "    return feature_vec\n",
    "            \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_operator(action : str, op_list: List[Operator]):\n",
    "    \"\"\"\n",
    "    find an operator from the planning graph's ground operator lists\n",
    "    \n",
    "    return: the action operator if found\n",
    "    \"\"\"\n",
    "    name_list = action.replace('(', '').replace(')', '').split(' ')\n",
    "    for op in op_list:\n",
    "        if op.operator_name == name_list[0]:\n",
    "            if list(op.variable_list.values()) == name_list[1:]: return op\n",
    "    return None\n",
    "\n",
    "def apply_operation(action: Operator, state : Set[Tuple]):\n",
    "    \"\"\"\n",
    "    apply an action onto the input state\n",
    "    \n",
    "    return: the new state\n",
    "    \"\"\"\n",
    "    new_state = state.copy()\n",
    "    for eff in action.effect_pos:\n",
    "        new_state.add(eff)\n",
    "    for eff in action.effect_neg:\n",
    "        new_state.remove(eff)\n",
    "    return new_state\n",
    "\n",
    "def read_plan(plan_file_path: str):\n",
    "    \"\"\"\n",
    "    read all the lines from a plan file directory, remove the last line containing cost\n",
    "    \n",
    "    return: a list containing the ground truth plan with length equal to total cost\n",
    "    \"\"\"\n",
    "    with open(plan_file_path, \"r\") as f:\n",
    "\n",
    "        # Read the lines of the file into a list of strings\n",
    "        lines = [line.strip() for line in f.readlines()]\n",
    "\n",
    "    return lines[:-1]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_training_data(domain_file_path, task_file_path, plan_file_path, problem_num : int, visual = False, max_level=10):\n",
    "    \"\"\"\n",
    "    generate the feature vector matrix X together with a cost vector y\n",
    "    \n",
    "    Returns:\n",
    "    X : array, shape (plan_length-1, n_features)\n",
    "        The input feature vec of states from initial states all the way towards the second-last state\n",
    "    y : array, shape (plan_length-1, 2)\n",
    "        The input cost vector. If it's a 2D array, the second column is the probelm_num\n",
    "    \"\"\"\n",
    "    \n",
    "    # generate graph\n",
    "    planning_graph = PlanningGraph(domain_file_path, task_file_path, visualize = visual)\n",
    "    graph = planning_graph.create(max_num_of_levels = max_level)\n",
    "    plan_actions = read_plan(plan_file_path)\n",
    "    ground_operators = planning_graph._planning_problem._get_ground_operators()\n",
    "    \n",
    "    # define output matrixes\n",
    "    X = []\n",
    "    y = []\n",
    "    \n",
    "    # loop from the final plan\n",
    "    current_state = planning_graph._planning_problem.initial_state\n",
    "    current_cost = len(plan_actions)\n",
    "    for i in range(0,len(plan_actions)-1):\n",
    "        X.append(generate_feature_vec(planning_graph, current_state, max_level))\n",
    "#         X.append(generate_feature_vec(planning_graph, current_state, max_level, visual = True, title = f\"test_image{i}th layer.png\"))\n",
    "        y.append(current_cost)\n",
    "        current_action = find_operator(plan_actions[i], ground_operators)\n",
    "        print(i, plan_actions[i],current_action.operator_name)\n",
    "        current_state = apply_operation(current_action, current_state)\n",
    "        current_cost -=1\n",
    "        \n",
    "    y = np.c_[y, problem_num * np.ones(len(y))]\n",
    "    return np.asarray(X), np.asarray(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 (unstack b4 b1) unstack\n",
      "1 (put-down b4) put-down\n",
      "2 (unstack b1 b2) unstack\n",
      "3 (put-down b1) put-down\n",
      "4 (pick-up b2) pick-up\n"
     ]
    }
   ],
   "source": [
    "X, y = generate_training_data('domain/blocks/domain.pddl', 'domain/blocks/blocks/blocks4/task01.pddl', 'domain/blocks/plans/blocks4-task01_1800.out', 5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(5, 39) (5, 2)\n",
      "<class 'numpy.ndarray'> <class 'numpy.ndarray'>\n",
      "[[1.4000000e+01 1.4000000e+01 3.8000000e+01 2.9000000e+01 0.0000000e+00\n",
      "  0.0000000e+00 1.0000000e+01 3.2000000e+01 2.8000000e+01 9.6000000e+01\n",
      "  0.0000000e+00 1.8000000e+01 2.4000000e+01 1.0000000e+01 0.0000000e+00\n",
      "  0.0000000e+00 1.1000000e+01 0.0000000e+00 5.5000000e+01 2.5000000e+01\n",
      "  3.0000000e+00 2.5000000e+01 0.0000000e+00 2.2000000e+01 1.1000000e+01\n",
      "  6.9000000e+01 3.3000000e+01 9.9000000e+01 1.1000000e+01 0.0000000e+00\n",
      "  5.0000000e+00 6.4000000e+01 5.1000000e+01 1.9900000e+02 3.1000000e+01\n",
      "  3.5000000e+01 7.0000000e+00 6.0000000e+00 8.3886080e+06]\n",
      " [1.2000000e+01 1.2000000e+01 3.4000000e+01 2.3000000e+01 0.0000000e+00\n",
      "  0.0000000e+00 8.0000000e+00 2.8000000e+01 2.4000000e+01 8.6000000e+01\n",
      "  0.0000000e+00 1.5000000e+01 2.2000000e+01 8.0000000e+00 0.0000000e+00\n",
      "  0.0000000e+00 7.0000000e+00 0.0000000e+00 4.6000000e+01 2.1000000e+01\n",
      "  3.0000000e+00 2.1000000e+01 0.0000000e+00 1.8000000e+01 1.1000000e+01\n",
      "  5.8000000e+01 2.8000000e+01 8.1000000e+01 7.0000000e+00 0.0000000e+00\n",
      "  5.0000000e+00 4.6000000e+01 3.7000000e+01 1.4200000e+02 1.9000000e+01\n",
      "  2.3000000e+01 6.0000000e+00 5.0000000e+00 1.6777216e+07]\n",
      " [2.0000000e+00 0.0000000e+00 0.0000000e+00 1.0000000e+00 0.0000000e+00\n",
      "  0.0000000e+00 0.0000000e+00 0.0000000e+00 0.0000000e+00 0.0000000e+00\n",
      "  0.0000000e+00 0.0000000e+00 0.0000000e+00 0.0000000e+00 0.0000000e+00\n",
      "  0.0000000e+00 0.0000000e+00 0.0000000e+00 0.0000000e+00 0.0000000e+00\n",
      "  0.0000000e+00 0.0000000e+00 0.0000000e+00 0.0000000e+00 0.0000000e+00\n",
      "  0.0000000e+00 0.0000000e+00 0.0000000e+00 0.0000000e+00 0.0000000e+00\n",
      "  0.0000000e+00 0.0000000e+00 0.0000000e+00 0.0000000e+00 0.0000000e+00\n",
      "  0.0000000e+00 2.0000000e+00 0.0000000e+00 2.0480000e+03]\n",
      " [0.0000000e+00 1.0000000e+00 3.0000000e+00 0.0000000e+00 0.0000000e+00\n",
      "  0.0000000e+00 0.0000000e+00 0.0000000e+00 0.0000000e+00 0.0000000e+00\n",
      "  0.0000000e+00 0.0000000e+00 0.0000000e+00 0.0000000e+00 0.0000000e+00\n",
      "  0.0000000e+00 0.0000000e+00 0.0000000e+00 0.0000000e+00 0.0000000e+00\n",
      "  0.0000000e+00 0.0000000e+00 0.0000000e+00 0.0000000e+00 0.0000000e+00\n",
      "  0.0000000e+00 0.0000000e+00 0.0000000e+00 0.0000000e+00 0.0000000e+00\n",
      "  0.0000000e+00 0.0000000e+00 0.0000000e+00 0.0000000e+00 0.0000000e+00\n",
      "  0.0000000e+00 2.0000000e+00 0.0000000e+00 8.1920000e+03]\n",
      " [4.0000000e+00 0.0000000e+00 0.0000000e+00 0.0000000e+00 0.0000000e+00\n",
      "  0.0000000e+00 0.0000000e+00 0.0000000e+00 0.0000000e+00 0.0000000e+00\n",
      "  0.0000000e+00 0.0000000e+00 0.0000000e+00 0.0000000e+00 0.0000000e+00\n",
      "  0.0000000e+00 0.0000000e+00 0.0000000e+00 0.0000000e+00 0.0000000e+00\n",
      "  0.0000000e+00 0.0000000e+00 0.0000000e+00 0.0000000e+00 0.0000000e+00\n",
      "  0.0000000e+00 0.0000000e+00 0.0000000e+00 0.0000000e+00 0.0000000e+00\n",
      "  0.0000000e+00 0.0000000e+00 0.0000000e+00 0.0000000e+00 0.0000000e+00\n",
      "  0.0000000e+00 2.0000000e+00 0.0000000e+00 8.1920000e+03]]\n",
      "<class 'numpy.float64'>\n"
     ]
    }
   ],
   "source": [
    "print(X.shape, y.shape)\n",
    "print(type(X), type(y))\n",
    "print(X)\n",
    "print(type(y[0,0]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# SVM PART"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import itertools\n",
    "import numpy as np\n",
    "import numpy.random as rd\n",
    "from sklearn import svm, linear_model\n",
    "from sklearn.model_selection import KFold\n",
    "from scipy import stats\n",
    "from svm import synthetic_data as sdata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test_data has shape: (28, 55)\n",
      "cost has shape: (28, 2)\n",
      "\n",
      "first vector in data set:\n",
      " [23.  8. 17. 12. 20.  2.  3.  2.  1.  1.  0.  2.  1.  2.  1.  3.  3.  4.\n",
      "  1.  2.  4.  1.  1.  1.  3.  3.  1.  2.  4.  3.  2.  2.  3.  3.  4.  2.\n",
      "  4.  3.  1.  4.  2.  4.  2.  1.  4.  4.  1.  2.  2.  2.  2.  0.  1.  3.\n",
      "  4.]\n",
      "\n",
      "first 7 element in cost vector:\n",
      " [[ 8  0]\n",
      " [15  0]\n",
      " [ 8  1]\n",
      " [39  1]\n",
      " [58  1]\n",
      " [37  1]\n",
      " [34  1]]\n",
      "the index for problems:  [ 0  2 11 18 20 28]\n"
     ]
    }
   ],
   "source": [
    "np.random.seed(2)\n",
    "# p_index, test_data, cost = sdata.create_synthetic_data(25, 7, 100, 5, 64, 23, 3)\n",
    "p_index, test_data, cost = sdata.create_synthetic_data(5, 5, 100, 2, 10, 23, 3)\n",
    "print(f\"test_data has shape: {test_data.shape}\\ncost has shape: {cost.shape}\\n\")\n",
    "print(\"first vector in data set:\\n\",np.round(test_data[0]))\n",
    "cost_display = cost[0:min(len(cost),7)]\n",
    "print(\"\\nfirst 7 element in cost vector:\\n\",cost_display)\n",
    "print(\"the index for problems: \",p_index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "implementation based on\n",
    "https://gist.github.com/agramfort/2071994\n",
    "\"\"\"\n",
    "\n",
    "import itertools\n",
    "import numpy as np\n",
    "\n",
    "from sklearn import svm, linear_model\n",
    "from sklearn.model_selection import KFold\n",
    "\n",
    "\n",
    "def transform_pairwise(X, y):\n",
    "    \"\"\"\n",
    "    Transforms data into pairs for convex relaxation of kendal rank correlation coef\n",
    "    In this method, all pairs are choosen, except for those that have the same target value or equal cost\n",
    "    Parameters\n",
    "    ----------\n",
    "    X : array, shape (n_samples, n_features)\n",
    "        The input feature vec of states from of several problems\n",
    "    y : array, shape (n_samples,) or (n_samples, 2)\n",
    "        The input cost vector. If it's a 2D array, the second column represents\n",
    "        the problem index\n",
    "    Returns\n",
    "    -------\n",
    "    X_trans : array, shape (k, n_feaures)\n",
    "        Paired difference of features of si - sj\n",
    "    y_trans : array, shape (k,)\n",
    "        Output rank labels of values {-1, +1}, 1 represent larger cost for si compared to sj\n",
    "    \"\"\"\n",
    "    X_new = []\n",
    "    y_new = []\n",
    "    if y.ndim == 1:\n",
    "        y = np.c_[y, np.ones(y.shape[0])]\n",
    "    comb = itertools.combinations(range(X.shape[0]), 2)\n",
    "    for k, (i, j) in enumerate(comb):\n",
    "        if y[i, 0] == y[j, 0] or y[i, 1] != y[j, 1]:\n",
    "            # skip if same target or different group\n",
    "            continue\n",
    "        X_new.append(X[i] - X[j])\n",
    "        y_new.append(np.sign(y[i, 0] - y[j, 0])) # y = 1 if feature vec got a larger cost\n",
    "        if y_new[-1] != (-1) ** k:\n",
    "            y_new[-1] = - y_new[-1]\n",
    "            X_new[-1] = - X_new[-1]\n",
    "    return np.asarray(X_new), np.asarray(y_new)\n",
    "\n",
    "\n",
    "class RankSVM(svm.LinearSVC):\n",
    "    \"\"\"\n",
    "    Performs pairwise ranking svm with an underlying LinearSVC model\n",
    "    initialise with a C of regularization term\n",
    "    default using hinge loss\n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(self, C = 1.0):\n",
    "        super(RankSVM, self).__init__()\n",
    "        self.C = C\n",
    "        self.loss = 'hinge'\n",
    "        \n",
    "        \n",
    "    def fit(self, X, y):\n",
    "        \"\"\"\n",
    "        Fit a pairwise ranking model.\n",
    "        Parameters\n",
    "        ----------\n",
    "        X : array, shape (n_samples, n_features)\n",
    "        y : array, shape (n_samples,) or (n_samples, 2)\n",
    "        Returns\n",
    "        -------\n",
    "        self\n",
    "        \"\"\"\n",
    "        X_trans, y_trans = transform_pairwise(X, y)\n",
    "        super(RankSVM, self).fit(X_trans, y_trans)\n",
    "        return self\n",
    "\n",
    "    def predict(self, X):\n",
    "        \"\"\"\n",
    "        Predict an ordering on X. For a list of n samples, this method\n",
    "        returns a list from 0 to n-1 with the relative order of the rows of X.\n",
    "        Parameters\n",
    "        ----------\n",
    "        X : array, shape (n_samples, n_features)\n",
    "        Returns\n",
    "        -------\n",
    "        ord : array, shape (n_samples,)\n",
    "            Returns a list of integers representing the relative order of\n",
    "            the rows in X.\n",
    "        \"\"\"\n",
    "        if hasattr(self, 'coef_'):\n",
    "            return np.argsort(np.dot(X, self.coef_.T).flatten())\n",
    "        else:\n",
    "            raise ValueError(\"Must call fit() prior to predict()\")\n",
    "\n",
    "    def score(self, X, y):\n",
    "        \"\"\"\n",
    "        Because we transformed into a pairwise problem, chance level is at 0.5\n",
    "        \"\"\"\n",
    "        X_trans, y_trans = transform_pairwise(X, y)\n",
    "        return np.mean(super(RankSVM, self).predict(X_trans) == y_trans)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "my_svm = RankSVM()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\anaconda\\lib\\site-packages\\sklearn\\svm\\_base.py:1206: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([4, 2, 3, 1, 0], dtype=int64)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "my_svm.fit(X, y)\n",
    "my_svm.predict(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "vscode": {
   "interpreter": {
    "hash": "f8dfbf299046a8c4b2110a11b95a75110c24cb97ab3ce5dec25bf2ee93348e3b"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
